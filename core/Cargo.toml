[package]
name = "xybrid-core"
version = "0.0.1"
edition = "2021"

[lib]
name = "xybrid_core"
path = "src/lib.rs"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_yaml = "0.9"
serde_json = "1.0"
anyhow = "1.0"
dirs = "5.0"
tar = "0.4"
zstd = "0.13"
sha2 = "0.10"
thiserror = "1.0"
uuid = { version = "1.0", features = ["v4"] }
chrono = "0.4"
bincode = "1.3"
ureq = { version = "2.8", default-features = false, features = ["json", "tls"] }
url = "2.5"
tokio = { version = "1.0", features = ["rt", "rt-multi-thread", "sync"] }
tempfile = "3.8"

# System information for device detection (v0.0.7)
sysinfo = "0.32"

# ONNX Runtime for model inference
# Note: Using ort crate for ONNX Runtime bindings
# For macOS/iOS: Uses CoreML/Metal backend
# For Android: Uses NNAPI backend (requires load-dynamic + AAR)
# For desktop: Uses CPU backend
# Note: Using default-features = false for cross-platform compatibility.
# - For Android: Use ort-load-dynamic feature (loads .so at runtime)
# - For other platforms: Use ort-download feature to download prebuilt binaries
ort = { version = "2.0.0-rc.10", default-features = false, features = ["ndarray", "std"] }
ndarray = "0.16"  # Used by ort for tensor operations
base64 = "0.21"  # For BPE token decoding
mel_spec = "0.2"  # For mel spectrogram computation (audio preprocessing)
num-complex = "0.4"  # Required by mel_spec for Complex numbers
rustfft = "6.2"  # For custom Whisper-compatible FFT (Slaney mel scale)
image = "0.25"  # For image resizing and processing
tokenizers = "0.19"  # For text tokenization (BERT, GPT, etc.)
hound = "3.5"  # For WAV file reading (audio preprocessing)
cmudict-fast = "0.8"  # For CMU pronouncing dictionary (TTS phonemization)
lazy_static = "1.4"  # For static CMU dictionary initialization
unicode-normalization = "0.1"  # For NFC normalization of IPA phonemes

# Kokoro TTS dependencies (v0.0.10)
# Note: espeak-ng phonemization now uses system command (no library linking required)
ndarray-npy = "0.9"  # For loading voice embeddings from npz files
regex = "1.10"  # For text normalization patterns

# Candle - Pure Rust ML framework (optional, for Whisper ASR)
# Enable with: cargo build --features candle
candle-core = { version = "0.8", optional = true }
candle-nn = { version = "0.8", optional = true }
candle-transformers = { version = "0.8", optional = true }
safetensors = { version = "0.4", optional = true }
hf-hub = { version = "0.3", optional = true }  # For downloading models from HuggingFace
byteorder = { version = "1.5", optional = true }  # For reading mel filter bytes
num-traits = { version = "0.2", optional = true }  # Required by candle audio

[features]
default = ["onnx-runtime", "ort-download"]
onnx-runtime = []
# Desktop/iOS/macOS: Download prebuilt ONNX Runtime binaries during build
ort-download = ["ort/download-binaries"]
# Android: Load ONNX Runtime dynamically at runtime (from AAR .so files)
# Note: When using ort-load-dynamic, don't enable ort-download
ort-load-dynamic = ["ort/load-dynamic"]
candle = ["dep:candle-core", "dep:candle-nn", "dep:candle-transformers", "dep:safetensors", "dep:hf-hub", "dep:byteorder", "dep:num-traits"]
candle-metal = ["candle", "candle-core/metal", "candle-nn/metal", ]
candle-cuda = ["candle", "candle-core/cuda"]

[dev-dependencies]
tempfile = "3.8"
xybrid-sdk = { path = "../sdk" }
dirs = "5.0"
filetime = "0.2"
hound = "3.5"  # WAV file reading for tests
walkdir = "2.4"  # For directory traversal in tests
ureq = { version = "2.8", default-features = false, features = ["json", "tls"] }  # For HTTP in tests
