---
title: Quick Start
description: Get up and running with Xybrid in minutes
---

Get Xybrid running in your app with a few lines of code. Choose your SDK below.

<Tabs items={['Flutter', 'Swift', 'Kotlin', 'Unity', 'CLI']}>
  <Tab value="Flutter">
**Install**

```yaml
# pubspec.yaml
dependencies:
  xybrid_flutter: ^0.1.0
```

```bash
flutter pub get
```

**Run inference**

```dart
import 'package:xybrid_flutter/xybrid_flutter.dart';

await RustLib.init();

// Load a model and run text-to-speech
final model = await Xybrid.model(modelId: 'kokoro-82m').load();
final result = await model.run(
  envelope: Envelope.text(text: "Hello from Xybrid!"),
);

// result.audioBytes contains the generated speech audio
```

**Expected output:** Audio bytes containing synthesized speech.
  </Tab>
  <Tab value="Swift">
**Install**

Add via Swift Package Manager in Xcode:

**File > Add Package Dependencies** and enter:

```
https://github.com/xybrid-ai/xybrid
```

Or add to `Package.swift`:

```swift
dependencies: [
    .package(url: "https://github.com/xybrid-ai/xybrid", from: "0.1.0")
]
```

**Run inference**

```swift
import Xybrid

// Load a model from the registry
let loader = XybridModelLoader.fromRegistry(modelId: "kokoro-82m")
let model = try loader.load()

// Run text-to-speech
let envelope = XybridEnvelope.text(text: "Hello from Xybrid!")
let result = try model.run(envelope: envelope)

// result.audioBytes contains the generated speech audio
```

**Expected output:** `result.success == true` with audio bytes in `result.audioBytes`.
  </Tab>
  <Tab value="Kotlin">
**Install**

```kotlin
// build.gradle.kts
dependencies {
    implementation("ai.xybrid:xybrid:0.1.0")
}
```

**Run inference**

```kotlin
import ai.xybrid.XybridModelLoader
import ai.xybrid.XybridEnvelope

// Load a model from the registry
val loader = XybridModelLoader.fromRegistry("kokoro-82m")
val model = loader.load()

// Run text-to-speech
val envelope = XybridEnvelope.Text(text = "Hello from Xybrid!")
val result = model.run(envelope)

// result.audioBytes contains the generated speech audio
```

**Expected output:** `result.success == true` with audio bytes in `result.audioBytes`.
  </Tab>
  <Tab value="Unity">
**Install**

In Unity, go to **Window > Package Manager > + > Add package from git URL** and enter:

```
https://github.com/xybrid-ai/xybrid.git?path=bindings/unity
```

Or add to `Packages/manifest.json`:

```json
{
  "dependencies": {
    "ai.xybrid.sdk": "https://github.com/xybrid-ai/xybrid.git?path=bindings/unity"
  }
}
```

**Run inference**

```csharp
using Xybrid.Native;
using UnityEngine;

// Initialize the SDK
NativeMethods.xybrid_init();

// Create a model loader and load a model
var loader = NativeMethods.xybrid_model_loader_new();
NativeMethods.xybrid_model_loader_load(loader, "kokoro-82m", IntPtr.Zero, out var model);

// Run text-to-speech
var envelope = NativeMethods.xybrid_envelope_new_text("Hello from Xybrid!");
NativeMethods.xybrid_model_run(model, envelope, out var output);

// Get the result
var textPtr = NativeMethods.xybrid_result_get_text(output);
Debug.Log($"Result: {Marshal.PtrToStringUTF8(textPtr)}");
```

**Expected output:** Audio result from the TTS model, accessible via the result pointer.
  </Tab>
  <Tab value="CLI">
**Install**

```bash
cargo install xybrid-cli
```

**Run inference**

```bash
# List available models
xybrid models list

# Run text-to-speech
xybrid run kokoro-82m --input "Hello from Xybrid!" --output hello.wav

# Run speech-to-text
xybrid run whisper-tiny --input recording.wav
```

**Expected output:**

```
Transcription: "Hello, how can I help you?"
```
  </Tab>
</Tabs>

## Next Steps

<Cards>
  <Card title="SDKs" href="/docs/integrations/sdks" description="Detailed SDK guides for each platform" />
  <Card title="Pipelines" href="/docs/concepts/pipelines" description="Chain multiple models together" />
  <Card title="Concepts" href="/docs/concepts" description="How Xybrid works under the hood" />
</Cards>
